\documentclass{article}


\usepackage{amsmath,amssymb,scalerel,amsthm}
\usepackage[margin=0.2in]{geometry}
\usepackage{derivative}
\usepackage{mathtools}
\usepackage{color}


\title{Calculus II}
\author{Alessio Esposito}

\newtheorem{theorem}{Theorem}
\newtheorem{observation}{Obs}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem*{schwarztheorem}{Theorem (Schwartz)}


\begin{document}
\maketitle

    \begin{theorem}
        $A$ is closed $\Longleftrightarrow$ every accumulation point for $A$ is in $A$ \hfill    
    \end{theorem}
    \begin{proof}
        $"\Longrightarrow"$ Let $A \subseteq \mathbb{R}^n, \ A = A \cup \partial A. \\$ Then $\forall  p \in \bar{\mathcal{D}} (A), \ C_r(p)_{\diagdown p}\cap A \neq \emptyset \ \forall  C \in \mathcal{C}_p.$ \\
        if $ p \notin A $ then $C_r(p)$ has elements that dont belong to $A \Rightarrow p \in \partial A.$ \\
        $"\Longleftarrow"$ Let $p \in \partial A \Rightarrow \forall C \in \mathcal{C}_p$ of center $r$ with $r \in \mathbb{R}$ by definition we can find some $x \in C_{\diagdown p} \cap A, $ so that means $p \in \bar{\mathcal{D}} (A) \Rightarrow p \in A.$       
    \end{proof}

\section{Limits}

    \begin{definition}
        Let $A \subseteq \mathbb{R}^2$ and $(x_0,y_0)$ an accumulation point for $A.$ we define $A^*$ as follows: \\ 
        $A^* = \{(\rho , \theta) \in [0, +\infty ] \times [0, 2\pi] : (x_0 + \rho \cos(\theta), y_0 + \rho \sin(\theta)) \in A \}.$

    \end{definition}
        
    \begin{proposition}
        Lets suppose that exist a circle $C$ of center $(x_0,y_0)$ such that $C_{\diagdown \{ (x_0,y_0) \}} \subseteq A$ let $r$ be the radius of the circle and as a consequence $(0,r] \times [0,2\pi] \subseteq A^*$
    \end{proposition}
    
    \begin{proof}
        Let $C_{\diagdown \{ (x_0,y_0) \}}$ and
            $\begin{cases}
                0 < \rho \leqslant r \\
                0 \leqslant \theta \leqslant 2\pi
            \end{cases}$
            if $(\rho, \theta) \in (0,r] \times [0,2\pi]$ \\ then $(x_0 + \rho \cos(\theta), y_0 + \rho \sin(\theta)) \in C_{\diagdown \{ (x_0,y_0) \}} \subseteq A \Rightarrow (\rho, \theta) \in A^*$.
    \end{proof}
        
    \begin{definition}
        Let $\theta \in [0,2\pi]$ and $\forall \rho \in (0,r]$ we define $\varphi_\theta(\rho) = F(\rho, \theta)$ if $\rho \in (0,r], (\rho, \theta) \in A^*$ so the $\lim_{\rho \to 0} \varphi(\rho) = l \in \bar{\mathbb{R}}$. \\
        If that limit exists that means $\forall \theta \in [0, 2\pi]$ and $\forall \varepsilon > 0$, $\exists \delta > 0 \ \forall \rho \in (0,r]$ with $\rho < \delta \ \left\lvert \varphi_\theta - l \right\rvert < \varepsilon.$ \\
        We say that $\lim_{\rho \to 0} \varphi(\rho) = l \in \bar{\mathbb{R}} $ Uniformly With Respect To $(U.W.R.T.) \ \theta.$     
    \end{definition}
            
    \begin{theorem}
        Let $f:A\subseteq \mathbb{R}^2 \rightarrow \mathbb{R} $ with $(x_0,y_0)$ accumulation point for $A.$ \\ Follows the equivalence: \\ $\lim_{(x,y) \to (x_0,y_0)} f(x,y) = l \in \bar{\mathbb{R}} \Longleftrightarrow \lim_{\rho \to 0} F(\rho, \theta ) = l \ U.W.R.T. \ \theta.$ 
    \end{theorem}

    \begin{proof}
        Let $l \in \bar{\mathbb{R}}. \\$
        $"\Longrightarrow" \ \lim_{(x,y) \to (x_0, y_0)} f(x,y) = l$ so $\forall \varepsilon > 0, \exists \delta > 0: \forall \ (x,y) \in A$ \\ with $\left\lVert (x,y) - (x_0,y_0)\right\rVert < \delta, \ \left\lvert f(x,y) - l \right\rvert < \varepsilon. \\ \\$
        We have to prove that $\forall \varepsilon > 0, \ \exists \delta > 0 : \forall \theta \in [0,2\pi], \ \forall \rho (0,r] \\$ with $\rho < \delta \ \left\lvert F(\rho, \theta) - l\right\rvert < \varepsilon. \\$
        Let $\varepsilon > 0, \ \theta \in [0,2\pi], \ \rho \in (0,r]$ with $\rho < \delta.$ we create the system that changes the coordinates from cartesians to polars:
        \begin{equation*}
            \begin{cases}
                x = x_0 + \rho \cos(\theta) \\
                y = y_0 + \rho \sin(\theta) 
            \end{cases} \rho = \sqrt{(x - x_0)^2 + (y - y_0)^2} 
        \end{equation*}
        $\rho \in (0,r], \ \theta \in [0,2\pi] \in (0,r] \times [0,2\pi] \subseteq A^*, \ (\rho,\theta) \in A^* \Rightarrow (x,y) \in A. \\ \\$ 
        Now $ 0 < \sqrt{(x - x_0)^2 + (y - y_0)^2} = \rho < \delta \Rightarrow \left\lvert f(x,y) - l \right\rvert < \varepsilon. \\ $
        $\Rightarrow \left\lvert f(x_0 + \rho \cos(\theta), y_0 + \rho \sin(\theta)) - l \right\rvert < \varepsilon \Rightarrow \left\lvert F(\rho, \theta) - l \right\rvert < \varepsilon. \\ \\$
        $"\Longleftarrow" \ \forall \varepsilon > 0, \exists \delta \leq r : \forall \theta \in [0,2\pi]$ and $\forall \rho$ with $ 0 < \rho < \delta \Rightarrow \\ \left\lvert F(\rho, \theta) - l \right\rvert < \varepsilon. \\$
        We have to prove that $\forall \varepsilon > 0, \exists \delta > 0, \forall (x,y) \in A$ with \\ $ \sqrt{(x - x_0)^2 + (y - y_0)^2} = \left\lVert (x,y) - (x_0,y_0) \right\rVert  < \delta \Rightarrow \left\lvert f(x,y) - l \right\rvert < \varepsilon. \\ \\$
        Let $\varepsilon > 0, \ \delta \leq r, \ (x,y) \in A, \ \sqrt{(x - x_0)^2 + (y - y_0)^2} < \delta,$ we switch coordinates with $\rho$ and $\theta$ as follows:
            \begin{equation*}
                \begin{cases}
                    x = x_0 + \rho \cos(\theta) \\
                    y = y_0 + \rho \sin(\theta)  
                \end{cases} \rho = \sqrt{(x - x_0)^2 + (y - y_0)^2} 
            \end{equation*}
        $0< \rho < \delta \leq r \Rightarrow \rho \in (0,r), \ \theta \in [0,2\pi]. \\$ 
        We notice that $ \left\lvert F(\rho, \theta) - l \right\rvert < \varepsilon,$ so $ \left\lvert f(x_0 + \rho \cos(\theta), y_0 + \rho \sin(\theta)) - l \right\rvert < \varepsilon \\$
        $ \Rightarrow  \left\lvert f(x,y) - l \right\rvert < \varepsilon.$
    \end{proof}
    \begin{definition}
        We say that $\theta \in [0,2\pi]$ is admissible if $ 0\in \bar{\mathcal{D}}(A_\theta).$
    \end{definition}
    \begin{definition}
        Let's suppose that $\lim_{\rho \to 0} F(\rho, \theta) = l \in \mathbb{R}$ then $\forall \rho \in (0,r], \ \varphi$
    \end{definition}
    \begin{theorem}
        $\lim_{\rho \to 0} F(\rho, \theta) = l \in \bar{\mathbb{R}} \ U.W.R.T. \ \theta \Longleftrightarrow \lim_{\rho \to 0 } \varphi(\rho) = 0.$
    \end{theorem}
    \begin{corollary}
        $\lim_{\rho \to 0} F(\rho, \theta) = l \in \bar{\mathbb{R}} \ U.W.R.T. \ \theta \Longleftrightarrow \exists$ a function $\psi(\rho)$ such that $\lim_{\rho \to 0} \psi(\rho) = 0$ and $\forall \theta \ \left\lvert F(\rho, \theta) - l\right\rvert \leqslant \psi(\rho).$
    \end{corollary}
    \begin{corollary}
        Let's suppose that $\lim_{\rho \to 0} F(\rho, \theta) = +\infty. \\ \forall \rho \in (0,r]$ let $h(\rho) = inf\{F(\rho, \theta) : \theta \in [0,2\pi] \}$ so then $\lim_{\rho \to 0} F(\rho, \theta) = +\infty \ U.W.R.T. \ \theta \Longleftrightarrow \lim_{\rho \to 0} h(\rho) = +\infty $
    \end{corollary}
    \begin{observation}
        $\lim_{\rho \to 0} F(\rho, \theta) = +\infty \ U.W.R.T. \ \theta \Longleftrightarrow \exists$ a function $K(\rho) \ s.t. \\ \lim_{\rho \to 0}K(\rho) = +\infty$ and $F(\rho,\theta) \geq K(\rho)$ 
    \end{observation}
    \begin{corollary}
        Let's suppose that $\lim_{\rho \to 0} F(\rho, \theta) = -\infty. \\ \forall \rho \in (0,r]$ let $g(\rho) = sup\{F(\rho, \theta) : \theta \in [0,2\pi] \}$ so then $\lim_{\rho \to 0} F(\rho, \theta) = -\infty \ U.W.R.T. \ \theta \Longleftrightarrow \lim_{\rho \to 0} g(\rho) = -\infty$
    \end{corollary}
    \begin{definition}
        Let $f : A \subseteq \mathbb{R}^2 \rightarrow \mathbb{R}$ with $A$ open.\\
        let $(x_0,y_0) \in A$, $\varphi(x) = f(x,y_0)$ and $\psi = f(x_0,y)$.
        $A$ is open that means that those two functions are well defined. 
    \end{definition}
    \subsection*{Differentiability}
    \begin{definition}
        Let be $f : A \subseteq \mathbb{R}^n \rightarrow \mathbb{R}$ with $A$ Open.
        Let $\bar{x} \in A$ and let $i \leq n$, we denote as $\varphi_i(x_i) = f(\bar{x}_1, \bar{x}_2, ... ,\bar{x}_{i-1},\bar{x}_i, \bar{x}_{i+1}, ... , \bar{x}_n)$. \
        Notice that $\bar{x}$ is an internal point so then it exist an interval where $\varphi_i$ is well defined. 
    \end{definition}
    \begin{definition}
        We say that $f$ is partially derivable with respect to the variable $x_i$ in the point $\bar{x}$ if $\varphi_i$ is derivable in that point.
        We denote as $\frac{\partial f}{\partial x_i}$ the partial derivative with respsect to $x_i$ in the point $\bar{x}$. 
    \end{definition}
    \begin{definition}
        The gradient of a function in $n$ variables is defined as follows:
        \begin{equation*}
            \nabla f : \bar{x} \in A \longmapsto  \left( \frac{\partial f}{\partial x_1},..., \frac{\partial f}{\partial x_n} \right)  \in \mathbb{R}^n
        \end{equation*}
    \end{definition}
    Let $f : A \subseteq \mathbb{R}^2 \rightarrow \mathbb{R}$ with $A$ open, and let $(x_0,y_0) \in A$. \\ $(x_0,y_0, f(x_0,y_0)) \in \mathcal{G}(f)$. The equation of the plane that passes for \\ $(x_0,y_0, f(x_0,y_0))$ is $Z = f(x_0,y_0) + a(X-x_0) + b(Y-y_0)$ where $a,b \in \mathbb{R}$.
    \begin{definition}
        We say that $f$ is partially derivable with respect to $x$ in $(x_0,y_0)$ if $\varphi$ is differentiable in $x_0$.
        in that case we $\varphi$ is the partial derivative of $f$ in the variable $x$ and its written $\frac{\partial f}{\partial x}$ 
    \end{definition}
    \begin{definition}
        We define the gradient as $\nabla f : (x,y) \in A \longmapsto \left( \frac{\partial f}{\partial x},\frac{\partial f}{\partial y} \right) \in \mathbb{R}^2$
    \end{definition}
    \begin{definition}
        We say that $f$ is differentiable in the point $(x_0, y_0)$ if exists $a,b \in \mathbb{R}$ such that:
        \begin{equation*}
            \lim_{(x, y) \to (x_0,y_0)} \frac{f(x,y)-f(x_0,y_0)-a(X-x_0)-b(Y-y_0)}{\left\lVert (x,y) - (x_0,y_0)\right\rVert } = 0  \ (\vartriangle) 
        \end{equation*}
        f is differentiable in the point $(x_0,y_0)$ if exists a plane that passes in the point $(x_0,y_0, f(x_0,y_0))$ that approximates the graph of the function $f$.
        \begin{proposition}
            If $f$ is differentiable in the point $(x_0,y_0)$, $f$ is partially derivable with respsect to $x$ and $y$ such that $a = \frac{\partial f(x_0,y_0)}{ \partial x}$ and $b = \frac{\partial f(x_0,y_0)}{ \partial y}$  
        \end{proposition}
        \begin{definition}
            if $f$ is differentiable in a point $(x,y) \in A$, the differential in the point is defined as follows:
            \begin{gather*}
                d_{(x,y)}f:(h,k) \in \mathbb{R}^2 \longmapsto \frac{\partial f(x,y)}{\partial x}h + \frac{\partial f(x,y)}{\partial y}k \in \mathbb{R}
            \end{gather*}
        \end{definition}
        \begin{definition}
            More in general if $f:A \subseteq \mathbb{R}^n \rightarrow \mathbb{R}$ and \textbf{x} $\in A$:
            \begin{equation*}
                d_{\textbf{x}}^rf:h \in \mathbb{R}^n \longmapsto \sum_{\substack{i_1, \dots, i_n \geqslant 0 \\ i_1 + \dots + i_n = r}}\frac{r!}{i_1! \dots i_n!}\frac{\partial ^r f}{\partial x^{i_1} \dots \partial x^{i_n}}(\textbf{x}) h^{i_1}_1, \dots,h^{i_n}_n  \in \mathbb{R}
            \end{equation*}
        \end{definition}
        \begin{corollary}
            $f$ is differentiable in the point $(x_0,y_0) \Longleftrightarrow f$ is partially derivable in the point $(x_0,y_0)$ and the $(\vartriangle)$ is true.
        \end{corollary}
    \newpage
        \begin{theorem}
            Let $f : A \subseteq \mathbb{R}^2 \rightarrow \mathbb{R}$ with $A$. If $\exists \ \frac{\partial f}{\partial x}$ and $\frac{\partial f}{\partial y}$ in $A$ and are continuos in a point $(x_0,y_0)$, then the function is differentiable in $(x_0,y_0)$.
            \begin{proof}
                We have to prove that:
                \begin{equation*}
                    \lim_{(x,y) \to (x_0,y_0)}\frac{f(x,y) - f(x_0,y_0) - \frac{\partial f(x_0,y_0)}{\partial x}(x-x_0) - \frac{\partial f(x_0,y_0)}{\partial y}(y-y_0)}{\sqrt{(x-x_0)^2 + (y-y_0)^2}} = 0
                \end{equation*}
                Lets add and subtract $f(x,y_0)$, so one has:
                \begin{equation*}
                    f(x,y) - f(x_0,y_0) = f(x,y) - f(x,y_0) + f(x,y_0) - f(x_0,y_0)
                \end{equation*} 
                We call $\varphi (t) = f(x,t)$ where $t \in I[y,y_0]$ and $I[y,y_0] = \begin{cases}
                    [y,y_0] \ y \leq y_0 \\
                    [y_0,y] \ y_0 \leq y
                \end{cases}$ \\
                $\varphi$ is derivable and for the Lagrange theorem $\exists y_1 \in I[y,y_0] : \varphi (y) - \varphi (y_0) = \dot{\varphi}(y_1)(y-y_0)$. So one has $f(x,y) - f(x,y_0) = \frac{\partial f(x,y_1)}{\partial y}(y-y_0)$, and we repeat the same reasoning for the other variable and one will have $f(x,y_0) - f(x_0,y_0) = \frac{\partial f(x_1,y_0)}{\partial x}(x-x_0)$
                We have then: 
                    \begin{gather*}
                        \left\lvert \frac{f(x,y) - f(x_0,y_0) - \frac{\partial f(x_0,y_0)}{\partial x}(x-x_0) - \frac{\partial f(x_0,y_0)}{\partial y}(y-y_0)}{\sqrt{(x-x_0)^2 + (y-y_0)^2}} \right\rvert = \\ = \left\lvert \frac{\frac{\partial f(x_1,y_0)}{\partial x}(x-x_0) - \frac{\partial f(x,y_1)}{\partial y}{(y-y_0) - \frac{\partial f(x_0,y_0)}{\partial x}(x-x_0) - \frac{\partial f(x_0,y_0)}{\partial y}(y-y_0)}}{\sqrt{(x-x_0)^2 + (y-y_0)^2}} \right\rvert = \\ = \left\lvert \frac{\left(\frac{\partial f (x_1,y_0)}{\partial x} - \frac{\partial f (x_0,y_0)}{\partial x} \right)(x-x_0) + \left( \frac{\partial f (x,y_1)}{\partial x} - \frac{\partial f(x_0,y_0)}{\partial x}\right)(y-y_0)}{\sqrt{(x-x_0)^2 + (y-y_0)^2}}\right\rvert  
                    \end{gather*}
                The last member is increased by the following:
                    \begin{gather*}
                        \left\lvert \frac{\partial f(x_1,y_0)}{\partial x} - \frac{\partial f(x_0,y_0)}{\partial x} \right\rvert \frac{\left\lvert x - x_0\right\rvert}{\left\lVert (x-x_0,y-y_0)\right\rVert } + \left\lvert \frac{\partial f(x,y_1)}{\partial y} - \frac{\partial f(x_0,y_0)}{\partial y}\right\rvert \frac{\left\lvert y - y_0\right\rvert}{\left\lVert (x-x_0,y-y_0) \right\rVert } \leq \\ \leq \left\lvert \frac{\partial f(x_1,y_0)}{\partial x} - \frac{\partial f(x_0,y_0)}{\partial x} \right\rvert + \left\lvert \frac{\partial f(x,y_1)}{\partial y} - \frac{\partial f(x_0,y_0)}{\partial y}\right\rvert
                    \end{gather*}
                And since $x \to x_0 \Rightarrow x_1 \to x_0$ and $y \to y_1 \Rightarrow y_1 \to y_0$ so the second member of the inequality is equal to zero.
            \end{proof}
        \end{theorem}
    \end{definition}
    \begin{theorem} %$\left( \diamondsuit \right)$ 
        Let $f : A \subseteq \mathbb{R}^n \rightarrow \mathbb{R}$ with $A$ open. If the function is differentiable in a point \textbf{x} $\in A$ then is continuos in that point.
        \begin{proof}
            Since we have:
            \begin{equation*}
                \lim_{x \to \textbf{x}}\frac{f(x) - f(\textbf{x}) - \sum_{i = 1}^{n} \frac{\partial f(\textbf{x})}{\partial x_i} \left(x_i - \textbf{x}_i \right)}{\left\lVert x - \textbf{x}\right\rVert} = 0
            \end{equation*}
            If we fix an $\varepsilon = 1$ there exists $\delta > 0 : \forall x \in A$ with $0 < \left\lVert x - \textbf{x} \right\rVert < \delta$ one has:
            \begin{equation*}
                \left\lvert \frac{f(x) - f(\textbf{x}) - \nabla f(\textbf{x})(x - \textbf{x})}{\left\lVert x - \textbf{x}\right\rVert} \right\rvert < \varepsilon \Longrightarrow \left\lvert f(x) - f(\textbf{x}) - \nabla f(\textbf{x})(x - \textbf{x}) \right\rvert < \left\lVert x - \textbf{x}\right\rVert
            \end{equation*}
            So we have the the following:
            \begin{equation*}
                \left\lvert f(x) - f(\textbf{x}) \right\rvert - \left\lvert \nabla f(\textbf{x})(x - \textbf{x}) \right\rvert \leq \left\lvert f(x) - f(\textbf{x}) - \nabla f(\textbf{x})(x - \textbf{x}) \right\rvert < \left\lVert x - \textbf{x}\right\rVert \ \bigtriangleup 
            \end{equation*}
            The $\bigtriangleup$ implies that $\left\lvert f(x) - f(\textbf{x}) \right\rvert - \left\lvert \nabla f(\textbf{x})(x - \textbf{x}) \right\rvert \leq \left\lvert \nabla f(\textbf{x})(x - \textbf{x}) \right\rvert + \left\lVert x - \textbf{x} \right\rVert \leq \left\lVert \nabla f(\textbf{x})\right\rVert \left\lVert x - \textbf{x} \right\rVert + \left\lVert x - \textbf{x} \right\rVert$. The last member of the inequality is equal to $\left\lVert x - \textbf{x} \right\rVert\left( \nabla f(\textbf{x}) + 1 \right)\vartriangle  $  so, if $ 0 < \left\lVert x - \textbf{x} \right\rVert < \delta$ then by calling the $\vartriangle = c$ one finally has:
            \begin{equation*}
                0 < \left\lvert f(x) - f(\textbf{x}) \right\rvert \leq c\left\lVert x - \textbf{x}\right\rVert \to 0 \Longleftrightarrow x \to \textbf{x} \Rightarrow \left\lvert f(x) - f(\textbf{x}) \right\rvert \to 0
            \end{equation*}
            Or equivalently: $\lim_{x \to \textbf{x}}f(x) = f(\textbf{x})$.
        \end{proof}
    \end{theorem}
    \newpage
    \begin{schwarztheorem}
        \footnote{$\Omega$ this time is used instead of $A$} Let $f:\Omega \subseteq \mathbb{R}^2 \rightarrow \mathbb{R}$ be a function in two variables defined on a open set $\Omega$. \\ If $f$ admits continous second derivatives in the point ($f \in C^2(\Omega)$) then $\frac{\partial ^2 f}{\partial x \partial y} = \frac{\partial ^2 f}{\partial y \partial x}$.
        \begin{proof}
            Let $p = (x_0,y_0) \in \Omega$ and chose two real numbers $\varepsilon,\delta > 0$ such that $(x_0 - \varepsilon, x_0 + \delta) \times (y_0 - \delta, y_0 + \delta) \subset \Omega$. That is possible since $\Omega$ is Open.
            Lets also define the two functions $F$ and $G$ as follows: 
            \begin{flalign*}
                F: (-\varepsilon,\varepsilon) \subset \mathbb{R} \rightarrow \mathbb{R} \\
                G: (-\delta,\delta) \subset \mathbb{R} \rightarrow \mathbb{R}
            \end{flalign*}
            In the way that:
            \begin{flalign*}
                F(t) = f(x_0 + t, y_0 + s) - f(x_0 + t,y_0) \ \ \forall s \in (- \delta, \delta) \\
                G(s) = f(x_0 + t, y_0 + s) - f(x_0,y_0 + s) \ \ \forall t \in (-\varepsilon, \varepsilon)
            \end{flalign*}
            It can be easily proved that: $F(t) - F(0) = G(s) - G(0)$ also if we apply the Lagrange theorem two times one has: $F(t) - F(0) = t\Dot{F}(\xi_1)$ with $t\Dot{F}(\xi_1)$ equal to: $t \left[ \frac{\partial f}{\partial x}(x_0 + \xi_1, y_0 + s) - \frac{\partial f}{\partial x}(x_0 + \xi_1,y_0) \right] = ts\frac{\partial ^2 f}{\partial y \partial x}(x_0 + \xi_1, y_0 + \sigma_1)$. The same reasoning can be applied to $G(s) - G(0)$ obtaining: $st\frac{\partial ^2 f}{\partial x \partial y}(x_0 + \xi_2, y_0 + \sigma_2)$ with $\xi_i \in (0,t)$ and $\sigma_i \in (0,s)$ where without loss of generality we can say $t,s > 0$. \\
            Thinking about $t \rightarrow 0$ and $s \rightarrow 0 \Rightarrow \xi_i \rightarrow 0$ and $\sigma_i \rightarrow 0$ with the continuity of the two derivatives one has: $\frac{ \partial ^2 f}{\partial y \partial x}(x_0,y_0) = \frac{ \partial ^2 f}{\partial x \partial y}(x_0,y_0)$.
        \end{proof}
    \end{schwarztheorem}
    \subsection*{Directional Derivatives}
    If we take $f : A \subseteq \mathbb{R}^2 \rightarrow \mathbb{R}$ defined on an open set $A$, $(x_0,y_0) \in A$ and a vector of unitary norm $\vec{v} = (v_1,v_2)$, the Directional derivative of $f(x_0,y_0)$ along the direction $\bar{v}$ can be defined as the limit if it exists and its finite:
    \begin{equation*}
        \frac{\partial f}{\partial \bar{v}}(x_0,y_0) = \lim_{t \to 0} \frac{f(x_0 + tv_1, y_0 + tv_2) - f(x_0,y_0) }{t}
    \end{equation*}
    \subsection*{Study of the maxima and minima}
        \begin{definition}
            If a partial derivative $\frac{\partial f}{\partial x}$ of a function $f : A \subseteq \mathbb{R}^2 \rightarrow \mathbb{R}$ is partially derivable with respect to $x$ in a point $(x_0,y_0) \in A$ we say that $f$ is partially derivable two times with respect to $x$ in the point $(x_0,y_0)$ ad it will be denoted as $\frac{\partial f}{\partial x}f_x(x_0,y_0)=\frac{\partial^2 f(x_0,y_0)}{\partial x^2} = \frac{\partial^2 f}{\partial x^2}(x_0,y_0)$. \\
            The same goes for the other partial derivatives: $\frac{\partial}{\partial y}f_x = \frac{\partial^2 f}{\partial x \partial y}$, $\frac{\partial}{\partial x}f_y = \frac{\partial^2 f}{\partial y \partial x}, \ldots $            
        \end{definition}
        \begin{definition}
            We define the hessian matrix as follows:
        \begin{equation*}
            \mathcal{D}^2f = \left(\begin{matrix}
                \frac{\partial^2 f}{\partial x^2} & \frac{\partial ^2 f}{\partial x \partial y} \\ \frac{\partial^2 f}{\partial y \partial x} & \frac{\partial ^2 f}{\partial y^2} 
            \end{matrix} \right)  
        \end{equation*}
        \end{definition}
        \begin{definition}
            The determinant of $\mathcal{D}^2f$ is: 
            \begin{equation*}
                \mathcal{H}(x,y) = \left\lvert \begin{matrix}
                \frac{\partial^2 f}{\partial x^2} & \frac{\partial ^2 f}{\partial x \partial y} \\ \frac{\partial^2 f}{\partial y \partial x} & \frac{\partial ^2 f}{\partial y^2} 
            \end{matrix} \right\rvert 
        \end{equation*} and is called the Hessian determinant.
        \end{definition}
        \begin{definition}
            Let $f : A \subseteq \mathbb{R}^2 \rightarrow \mathbb{R}$, we say that $(x_0,y_0) \in A$ is maxima (minima) for $f$ if $\forall (x,y) \in A, \ f(x,y) \leqslant f(x_0,y_0)$ \ ($f(x,y) \geqslant f(x_0,y_0)$). 
        \end{definition}
        \begin{theorem}
            If $f$ is continous and $A$ is compact, $f$ admits minima and maxima.
        \end{theorem}
        \begin{theorem}
            Let $f : A \subseteq \mathbb{R}^2 \rightarrow \mathbb{R}$ and let $(x_0,y_0) \in \dot{A}$ a relative extreme and let  $f$ be partially derivable in $(x_0,y_0)$, so then $\frac{\partial f(x_0,y_0)}{\partial x} = 0$ and $\frac{\partial f(x_0,y_0)}{\partial y} = 0$. \\
            The points where the partial derivatives are $0$ are said "critical points" of $f$, $(x_0,y_0) \in \dot{A}$ is an extreme ralative $\Rightarrow$ $(x_0,y_0)$ is a critical point for $f$ ($\nLeftarrow$).         
        \end{theorem}
        \begin{observation}
            Let $(x_0,y_0) \in A$ and let $g(x,y) = f(x,y) - f(x_0,y_0)$, $(x_0,y_0)$ is a relative minimum (relative maximum) for $f \Longleftrightarrow \ \exists$ a circle $C$ of center $(x_0,y_0)$ such that $g \geq 0$ ($g \leq 0$).
        \end{observation}
        \begin{theorem}
            Let $f : A \subseteq \mathbb{R}^2 \rightarrow \mathbb{R}$ and let $(x_0,y_0) \in \dot{A}$ a relative extreme $\Longrightarrow \mathcal{H}(x_0,y_0) \geqslant 0$.
        \end{theorem}
        \begin{theorem}
            Let $f : A \subseteq \mathbb{R}^2 \rightarrow \mathbb{R}$, $f \in \mathbf{C}^2$. Let $(x_0,y_0) \in \dot{A}$ a critical point and lets suppose that $\mathcal{H}(x_0,y_0) > 0 \Longrightarrow (x_0,y_0)$ is a relative extreme and is maximum or minimum depending on $\frac{\partial^2 f(x_0,y_0)}{\partial x^2}$ be $<0$ or $>0$.  
        \end{theorem}
\end{document}